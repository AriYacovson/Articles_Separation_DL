{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Config\n",
        "\n",
        "\n",
        "1.   importing librarys\n",
        "2.   checking gpu\n",
        "3.   mounting google drive\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sTVFovFmzTE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing all librarys\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import PIL.ImageShow\n",
        "import time\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "bOAMH_yhSU7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "5WR1fgaxb5L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep_xQP27XB9H"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fq5FQuH8STa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting Data to JPEG\n",
        "1. converting pdf to jpeg\n",
        "2. split catagories to their directory\n",
        "3. spliting to train, test, val"
      ],
      "metadata": {
        "id": "Ora5t5pnz_kv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6J8Qq9Hn0jlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "open_resize_and_label_png_directory"
      ],
      "metadata": {
        "id": "FGxQWOwzTfua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Loop through the dataset directory\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive/Articles_Seperation_DL/labeled_data'):\n",
        "    for file in files:\n",
        "        # Load the image using PIL\n",
        "        image_path = os.path.join(root, file)\n",
        "        try:\n",
        "          image = Image.open(image_path)\n",
        "\n",
        "          # Resize the image\n",
        "          image = image.resize((224, 224))\n",
        "          image = np.array(image)\n",
        "          image = image.reshape((224, 224, 1))\n",
        "\n",
        "          # Normalize the pixel values to [0, 1]\n",
        "          image = np.array(image) / 255.0\n",
        "\n",
        "\n",
        "          # Append the image and label to the respective lists\n",
        "          images.append(image)\n",
        "\n",
        "          # Extract the label from the directory name\n",
        "          label = os.path.basename(root)\n",
        "          labels.append(label)\n",
        "\n",
        "        except:\n",
        "          print(image_path, ' was not loaded succefully')"
      ],
      "metadata": {
        "id": "vV2Dp1tITobh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the lists to NumPy arrays\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "y = np.where(y == 'first_pages', 1, 0)"
      ],
      "metadata": {
        "id": "gB34saZwUMn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qNtnzERLXlbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Add a convolutional layer with 32 filters, a 3x3 kernel, and 'relu' activation\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 1)))\n",
        "\n",
        "# Add a max pooling layer with 2x2 pool size\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Add another convolutional layer with 64 filters and 'relu' activation\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Flatten the output from the previous layer\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Add a dense (fully connected) layer with 64 units and 'relu' activation\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "\n",
        "# Add an output layer with 1 unit and 'sigmoid' activation for binary classification\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "hYyGjAHaXld1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of epochs and batch size\n",
        "epochs = 10\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "KFUlSITQXlgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "# Print out the model's accuracy\n",
        "print('\\nTest loss:', test_loss)\n",
        "print('Test accuracy:', test_accuracy)\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "BY13MOIdOmcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to h5 file\n",
        "model.save('/content/drive/MyDrive/Articles_Seperation_DL/forth_model.h5')"
      ],
      "metadata": {
        "id": "9aNuq7psO71U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Articles_Seperation_DL/first_model.h5')"
      ],
      "metadata": {
        "id": "eW1GSM9ypvHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = model.predict(X_test).reshape(-1)\n"
      ],
      "metadata": {
        "id": "muoE8ouWe7j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_classes = (y_test_pred > 0.5)"
      ],
      "metadata": {
        "id": "pdZhPpx5fcj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistakes = np.where(y_test != y_test_pred_classes)[0]"
      ],
      "metadata": {
        "id": "-03repKmfcmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistakes_images = X_test[mistakes, :, :, :]"
      ],
      "metadata": {
        "id": "NB8Qtj5lfcp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mistakes_images.shape)"
      ],
      "metadata": {
        "id": "8Sm9mOX3gffm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tru_labels_of_mistakes = y_test[mistakes]"
      ],
      "metadata": {
        "id": "ah4FrZBxg_vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "img = Image.fromarray(mistakes_images[1].reshape(224, 224), mode='L')\n",
        "img.show()"
      ],
      "metadata": {
        "id": "xcZRYiFBiB4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(mistakes)):\n",
        "    img = Image.fromarray(mistakes_images[i].reshape(224, 224) * 255, mode='L')\n",
        "    img.save('/content/drive/MyDrive/Articles_Seperation_DL/'\n",
        "     + str(i) + 'true label' + str(tru_labels_of_mistakes[i]) + '.png')"
      ],
      "metadata": {
        "id": "9MrNJ76mgfiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7kF7WqngflJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVEUrsT0gfnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "metadata": {
        "id": "1oPva21lX3_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "utz58YZCupNA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}